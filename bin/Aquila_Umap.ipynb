{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysam\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==========================================================================================================\n",
    "fa_folder = \"/oak/stanford/groups/arend/Xin/AssemblyProj/reference_align_2/Software_Xin/Aquila/source\"     #The path of the folder which contains your fasta files\n",
    "fa_name = \"ref.fa\"               #The fasta file you want to process\n",
    "out_dir = \"/oak/stanford/groups/arend/Xin/LiuYC/test3\"            #The output folder direction (if not exist, the script will create one)\n",
    "start = 21                           #The start chromosome\n",
    "end = 21                            #The end chromosome.\n",
    "kmer_len = 100                      #Length of the kmers generated\n",
    "mapq_thres = 20                     #MAPQ filter threshold (20 recommended)\n",
    "bowtie_thread = 20                  #The number of parallel search threads bowtie2 would use \n",
    "#=========================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure variables above to meet your requirements, and run the following blocks one by one.\n",
    "\n",
    "NOTICE: You need to install Bowtie2 before running this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def QualStr (kmer_len):\n",
    "    #Generate a fake quality string, default k = 100\n",
    "    qual = ''\n",
    "    for i in range(kmer_len):\n",
    "        qual = qual+'~'\n",
    "    return qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QualStr function generates quality string for later use in generating .fq files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetGenome (fa_folder,fa_name):\n",
    "    genome ={}# key = chrnum ; item = chrseq\n",
    "    chro = []\n",
    "    with open(fa_folder+fa_name) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                if chro:\n",
    "                    genome[chrnum] = ''.join(chro)\n",
    "                    chro = []\n",
    "                    fw.close()\n",
    "                chrnum = line[1:].split(' ')[0].strip('\\n')\n",
    "                fw = open(fa_folder+chrnum+'.fa','w')\n",
    "                fw.write(line)\n",
    "            else:\n",
    "                chro.append(line.strip('\\n'))\n",
    "                fw.write(line)\n",
    "        genome[chrnum] = ''.join(chro)\n",
    "        chro = []\n",
    "    return genome # key : chrnum (chr21) value : chrseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GetGenome function splits the input fasta file by chromosome name, in other words, it generates some new fasta files and each of them only contains ONE chromosome. Meanwhile, GetGenome saves sequence information into the genome dictionary (key:chromosome name;value:chromosome sequence).\n",
    "\n",
    "Although this function assumes that the input fasta file contains multiple chromosomes, it is pretty okey if it only has one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenerateFqFile (chrseq,chrnum,qual,kmer_len):\n",
    "    with open(chrnum+'/'+chrnum+'.fq','w') as fw:\n",
    "        for n in range(len(chrseq)+1-kmer_len):\n",
    "            seq = chrseq[n:n+kmer_len]\n",
    "            if 'N' not in seq:\n",
    "                fw.write('@%s\\n%s\\n+\\n%s\\n'%(n+1,seq,qual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastq file content would be like:\n",
    "\n",
    "    @123456 \n",
    "    ATCGGTAC...\n",
    "    +\n",
    "    ~~~~~~~~...\n",
    "    \n",
    " (123456 is the kmer position)\n",
    " \n",
    " and saved as chrnum.fq eg:chr21.fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Bowtie2Map (chrnum,fa_folder,bowtie_thread):\n",
    "    thread = str(bowtie_thread)\n",
    "    os.chdir(chrnum+'/')\n",
    "    os.mkdir('./ref'+chrnum)\n",
    "    os.chdir('./ref'+chrnum)\n",
    "    #index folder is refchrnum eg:refchr21\n",
    "        \n",
    "    index_build = os.popen('bowtie2-build --threads '+thread +' '+fa_folder+chrnum+'.fa'+' ref'+chrnum,'r')\n",
    "    print(index_build.read())\n",
    "        \n",
    "    map_result = os.popen('bowtie2 -p '+thread+' -x '+'ref'+chrnum+' -U '+'../'+chrnum+'.fq '+'-S ../'+chrnum+'.sam','r')\n",
    "    print(map_result.read())\n",
    "    #output is chrnum.sam eg:chr21.sam\n",
    "        \n",
    "    os.chdir('..')\n",
    "    out1 = os.popen('samtools view -bS '+chrnum+'.sam'+' > '+chrnum+'.bam')\n",
    "    print(out1.read())\n",
    "    out2 = os.popen('samtools sort '+chrnum+'.bam -o '+chrnum+'.sorted.bam')\n",
    "    print(out2.read())\n",
    "    out3 = os.popen('samtools view -H '+chrnum+'.sorted.bam > header.sam')\n",
    "    print(out3.read())\n",
    "    out4 = os.popen('samtools view -F 4 '+chrnum+'.sorted.bam | grep -v \"XS:\" | cat header.sam - | samtools view -b - > unique'+chrnum+'.bam')\n",
    "    print(out4.read())\n",
    "    out5 = os.popen('rm header.sam')\n",
    "    print(out5.read())\n",
    "    out6 = os.popen('samtools index unique'+chrnum+'.bam')\n",
    "    print(out6.read())\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bowtie2Map uses Bowtie2 to get mapping result, and saves unique mapped reads to uniquechrnum.bam (eg:uniquechr1.bam).\n",
    "\n",
    "CAUTION: Make sure you have already installed samtools and Bowtie2 package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Filter(chrnum,mapq_thres,kmer_len):\n",
    "    filtered = []\n",
    "    bamfile = pysam.AlignmentFile(chrnum+'/'+'unique'+chrnum+'.bam',\"rb\")\n",
    "    for read in bamfile:\n",
    "        if int(read.mapq) >= mapq_thres and not (read.is_reverse):\n",
    "            filtered.append([int(read.pos),int(read.pos)+kmer_len-1])\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter function filters out reads which are reverse or MAPQ lower than threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Merge(chrnum,filtered):\n",
    "    start = 0\n",
    "    with open(chrnum+'/'+'merged.bed',\"w\") as fm:\n",
    "        for line in filtered:\n",
    "            if start == 0:\n",
    "                start,end = line[0],line[1]\n",
    "            elif line[0] > end+1:\n",
    "                fm.write(\"%s\\t%s\\t%s\\n\"%(chrnum,start,end))\n",
    "                start,end = line[0],line[1]\n",
    "            else:\n",
    "                end = line[1] \n",
    "        fm.write(\"%s\\t%s\\t%s\\n\"%(chrnum,start,end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge function merges those overlapping unique mapped kmers into bigger blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Get_uniqness(chrnum):\n",
    "    uniq_map = defaultdict(int)\n",
    "    with open(chrnum+'/'+\"merged.bed\",\"r\") as f:\n",
    "        with open(chrnum+'/'+\"500merged.bed\",\"w\") as fw:\n",
    "            for line in f:\n",
    "                data = line.rsplit()\n",
    "                _start = int(data[1])\n",
    "                _end = int(data[2])\n",
    "                block_len = _end - _start\n",
    "                if block_len >= 500:\n",
    "                    use_start = _start + 10\n",
    "                    use_end = _end - 10\n",
    "                    fw.write('%s\\t%s\\t%s\\n'%(chrnum,use_start, use_end))\n",
    "                    for step in range(use_start, use_end+1):\n",
    "                        uniq_map[step] = 1\n",
    "    pickle.dump(uniq_map,open(\"Uniqness_map/\"+\"uniq_map_\"+chrnum+\".p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get_uniqness function uses the merge results to get unique mapped keys and saves them into a pickle file, which is the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(fa_folder,out_dir,chrseq,chrnum,kmer_len,qual,mapq_thres,bowtie_thread):\n",
    "    print(\"Starting to process \"+chrnum)\n",
    "    t = time.time()\n",
    "    os.mkdir(chrnum)\n",
    "    \n",
    "    GenerateFqFile (chrseq,chrnum,qual,kmer_len)\n",
    "    print(chrnum,\":Generate .fq DONE\")\n",
    "    Bowtie2Map (chrnum,fa_folder,bowtie_thread)\n",
    "    print(chrnum,\":Bowtie2 mapping DONE\")\n",
    "    filtered = Filter(chrnum,mapq_thres,kmer_len)\n",
    "    print(chrnum,\":MAPQ filter DONE\")\n",
    "    Merge(chrnum,filtered)\n",
    "    print(chrnum,\":Merge DONE\")\n",
    "    Get_uniqness(chrnum)\n",
    "    print(chrnum,\":Get uniqness DONE\")\n",
    "    #-----------------------------------------------------------------------------------------------\n",
    "    out7 = os.popen('rm -R '+chrnum+'/')#These two lines delete the intermediate results. \n",
    "    print(out7.read())                   #If you want to keep those results, comment out these two.\n",
    "    #-----------------------------------------------------------------------------------------------\n",
    "    print(chrnum,\"DONE! Time used:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process chr21\n",
      "chr21 :Generate .fq DONE\n"
     ]
    }
   ],
   "source": [
    "fa_folder = fa_folder+\"/\"\n",
    "out_dir = out_dir+\"/\"\n",
    "chr_start = start - 1\n",
    "chr_end = end\n",
    "qual = QualStr(kmer_len)\n",
    "Genome = GetGenome(fa_folder,fa_name)\n",
    "chr_list = list(Genome.keys())\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "os.chdir(out_dir)\n",
    "    \n",
    "if not os.path.exists('Uniqness_map'):\n",
    "    os.mkdir('Uniqness_map')\n",
    "\n",
    "for chrnum in chr_list[chr_start:chr_end]:\n",
    "    chrseq = Genome[chrnum]\n",
    "    run(fa_folder,out_dir,chrseq,chrnum,kmer_len,qual,mapq_thres,bowtie_thread)\n",
    "\n",
    "for chrnum in chr_list:\n",
    "    os.popen('rm '+fa_folder+chrnum+'.fa')\n",
    "\n",
    "print(\"ALL DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

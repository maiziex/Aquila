{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================================================\n",
    "fa_folder = \"path/to/fafolder/\"     #The dir of the folder which contains your fasta files\n",
    "fa_name = \"sample.fa\"               #The fasta file you want to process\n",
    "out_dir = \"out/put/dir/\"            #The output folder which Aquila_Umap will output to\n",
    "start = 1                           #The start chromosome\n",
    "end = 23                            #The end chromosome.\n",
    "kmer_len = 100                      #Length of the kmers generated\n",
    "mapq_thres = 20                     #MAPQ filter threshold (20 recommended)\n",
    "bowtie_thread = 20                  #The number of parallel search threads bowtie2 would use \n",
    "#============================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure variables above to meet your requirements, and run the following blocks one by one.\n",
    "\n",
    "NOTICE: You need to install Bowtie2 before running this script.\n",
    "\n",
    "NOTICE: Some of the files generated during the process would take up a lot of storage (approximately 5~100G each, depending on the size of the chromosome). Although the script will remove them, be sure your disk has enough space remained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QualStr (kmer_len):\n",
    "    #Generate a fake quality string, default k = 100\n",
    "    qual = ''\n",
    "    for i in range(kmer_len):\n",
    "        qual = qual+'~'\n",
    "    return qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QualStr function generates quality string for later use in generating .fq files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGenome (fa_folder,fa_name):\n",
    "    genome ={}# key = chrnum ; item = chrseq\n",
    "    chro = []\n",
    "    with open(fa_folder+fa_name) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                if chro:\n",
    "                    genome[chrnum] = ''.join(chro)\n",
    "                    chro = []\n",
    "                    fw.close()\n",
    "                chrnum = line[1:].split(' ')[0].strip('\\n')\n",
    "                fw = open(fa_folder+chrnum+'.fa','w')\n",
    "                fw.write(line)\n",
    "            else:\n",
    "                chro.append(line.strip('\\n'))\n",
    "                fw.write(line)\n",
    "        genome[chrnum] = ''.join(chro)\n",
    "        chro = []\n",
    "    return genome # key : chrnum (chr21) value : chrseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GetGenome function splits the input fasta file by chromosome name, in other words, it generates some new fasta files and each of them only contains ONE chromosome. Meanwhile, GetGenome saves sequence information into the genome dictionary (key:chromosome name;value:chromosome sequence).\n",
    "\n",
    "Although this function assumes that the input fasta file contains multiple chromosomes, it is pretty okey if it only has one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateFqFile (chrseq,chrnum,chr_out_dir,qual,kmer_len):\n",
    "    with open(chr_out_dir+chrnum+'.fq','w') as fw:\n",
    "        for n in range(len(chrseq)+1-kmer_len):\n",
    "            seq = chrseq[n:n+kmer_len]\n",
    "            if 'N' not in seq:\n",
    "                fw.write('@%s\\n%s\\n+\\n%s\\n'%(n+1,seq,qual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastq file content would be like:\n",
    "\n",
    "    @123456 \n",
    "    ATCGGTAC...\n",
    "    +\n",
    "    ~~~~~~~~...\n",
    "    \n",
    " (123456 is the kmer position)\n",
    " \n",
    " and saved as chrnum.fq eg:chr21.fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bowtie2Map (chrnum,chr_out_dir,fa_folder,bowtie_thread):\n",
    "    thread = str(bowtie_thread)\n",
    "    os.chdir(chr_out_dir)\n",
    "    os.mkdir('./ref'+chrnum)\n",
    "    os.chdir('./ref'+chrnum)\n",
    "    #index folder is refchrnum eg:refchr21\n",
    "        \n",
    "    index_build = os.popen('bowtie2-build --threads '+thread +' '+fa_folder+chrnum+'.fa'+' ref'+chrnum,'r')\n",
    "    print(index_build.read())\n",
    "        \n",
    "    map_result = os.popen('bowtie2 -p '+thread+' -x '+'ref'+chrnum+' -U '+'../'+chrnum+'.fq '+'-S ../'+chrnum+'.sam','r')\n",
    "    print(map_result.read())\n",
    "    #output is chrnum.sam eg:chr21.sam\n",
    "        \n",
    "    os.chdir('..')\n",
    "    out1 = os.popen('samtools view -bS '+chrnum+'.sam'+' > '+chrnum+'.bam')\n",
    "    print(out1.read())\n",
    "    out2 = os.popen('samtools sort '+chrnum+'.bam -o '+chrnum+'.sorted.bam')\n",
    "    print(out2.read())\n",
    "    out3 = os.popen('samtools view -H '+chrnum+'.sorted.bam > header.sam')\n",
    "    print(out3.read())\n",
    "    out4 = os.popen('samtools view -F 4 '+chrnum+'.sorted.bam | grep -v \"XS:\" | cat header.sam - | samtools view -b - > unique'+chrnum+'.bam')\n",
    "    print(out4.read())\n",
    "    out5 = os.popen('rm header.sam')\n",
    "    print(out5.read())\n",
    "    out6 = os.popen('samtools index unique'+chrnum+'.bam')\n",
    "    print(out6.read())\n",
    "    out7 = os.popen('rm '+chrnum+'.fq')\n",
    "    print(out7.read())\n",
    "    out8 = os.popen('rm '+chrnum+'.sam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bowtie2Map uses Bowtie2 to get mapping result, and saves unique mapped reads to uniquechrnum.bam (eg:uniquechr1.bam).\n",
    "\n",
    "CAUTION: Make sure you have already installed samtools and Bowtie2 package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter(chrnum,chr_out_dir,mapq_thres,kmer_len):\n",
    "    filtered = []\n",
    "    bamfile = pysam.AlignmentFile(chr_out_dir+'unique'+chrnum+'.bam',\"rb\")\n",
    "    for read in bamfile:\n",
    "        if int(read.mapq) >= mapq_thres and not (read.is_reverse):\n",
    "            filtered.append([int(read.pos),int(read.pos)+kmer_len-1])\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter function filters out reads which are reverse or MAPQ lower than threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge(chrnum,filtered,chr_out_dir):\n",
    "    start = 0\n",
    "    with open(chr_out_dir+'merged.bed',\"w\") as fm:\n",
    "        for line in filtered:\n",
    "            if start == 0:\n",
    "                start,end = line[0],line[1]\n",
    "            elif line[0] > end+1:\n",
    "                fm.write(\"%s\\t%s\\t%s\\n\"%(chrnum,start,end))\n",
    "                start,end = line[0],line[1]\n",
    "            else:\n",
    "                end = line[1]b \n",
    "        fm.write(\"%s\\t%s\\t%s\\n\"%(chrnum,start,end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge function merges those overlapping unique mapped kmers into bigger blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_uniqness(chr_out_dir,Unique_dir,chrnum):\n",
    "    uniq_map = defaultdict(int)\n",
    "    with open(chr_out_dir+\"merged.bed\",\"r\") as f:\n",
    "        with open(chr_out_dir+\"500merged.bed\",\"w\") as fw:\n",
    "            for line in f:\n",
    "                data = line.rsplit()\n",
    "                _start = int(data[1])\n",
    "                _end = int(data[2])\n",
    "                block_len = _end - _start\n",
    "                if block_len >= 500:\n",
    "                    use_start = _start + 10\n",
    "                    use_end = _end - 10\n",
    "                    fw.write('%s\\t%s\\t%s\\n'%(chrnum,use_start, use_end))\n",
    "                    for step in range(use_start, use_end+1):\n",
    "                        uniq_map[step] = 1\n",
    "    pickle.dump(uniq_map,open(Unique_dir+\"uniq_map_\"+chrnum+\".p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get_uniqness function uses the merge results to get unique mapped keys and saves them into a pickle file, which is the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fa_folder,out_dir,chrseq,chrnum,kmer_len,qual,mapq_thres,bowtie_thread):\n",
    "    print(\"Starting to process \"+chrnum)\n",
    "    t = time.time()\n",
    "    os.chdir(out_dir)\n",
    "    os.mkdir(chrnum)\n",
    "    chr_out_dir = out_dir+chrnum+'/'\n",
    "    Unique_dir = out_dir+'Uniqness_map/'\n",
    "    \n",
    "    GenerateFqFile (chrseq,chrnum,chr_out_dir,qual,kmer_len)\n",
    "    print(chrnum,\":Generate .fq DONE\")\n",
    "    Bowtie2Map (chrnum,chr_out_dir,fa_folder,bowtie_thread)\n",
    "    print(chrnum,\":Bowtie2 mapping DONE\")\n",
    "    filtered = Filter(chrnum,chr_out_dir,mapq_thres,kmer_len)\n",
    "    print(chrnum,\":MAPQ filter DONE\")\n",
    "    Merge(chrnum,filtered,chr_out_dir)\n",
    "    print(chrnum,\":Merge DONE\")\n",
    "    Get_uniqness(chr_out_dir,Unique_dir,chrnum)\n",
    "    print(chrnum,\":Get uniqness DONE\")\n",
    "    \n",
    "    print(chrnum,\"DONE! Time used:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qual = QualStr(kmer_len)\n",
    "chr_start = start - 1\n",
    "chr_end = end\n",
    "Genome = GetGenome(fa_folder,fa_name)\n",
    "chr_list = list(Genome.keys())\n",
    "    \n",
    "os.chdir(out_dir)\n",
    "os.mkdir('Uniqness_map')\n",
    "    \n",
    "for chrnum in chr_list[chr_start:chr_end]:\n",
    "    chrseq = Genome[chrnum]\n",
    "    run(fa_folder,out_dir,chrseq,chrnum,kmer_len,qual,mapq_thres,bowtie_thread)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
